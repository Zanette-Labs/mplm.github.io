<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
      content="Message Passing Language Models (MPLMs): decentralized, efficient LLM reasoning with spawn/send/recv/stop directives and provable context savings.">
  <meta name="keywords"
        content="LLM, reasoning, message passing, MPLM, decentralized inference, fork-join, chain-of-thought, sudoku, structured reasoning">
  <title>MPLM: Message Passing Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro|JetBrains+Mono"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- KaTeX for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    :root {
      --primary: #1e40af;
      --primary-light: #3b82f6;
      --text-dark: #1f2937;
      --text-muted: #6b7280;
      --bg-white: #ffffff;
      --bg-gray: #f9fafb;
      --border-light: #e5e7eb;
    }
    
    body { color: var(--text-dark); }
    
    .hero { background: #fff; border-bottom: 1px solid #e5e7eb; }
    .hero .title.is-1 { color: #1f2937; font-weight: 700; }
    .hero .publication-authors a { color: #1e40af !important; }
    .hero .publication-authors a:hover { color: #3b82f6 !important; text-decoration: underline; }
    .hero .publication-authors span { color: #4b5563; }
    
    .publication-links .button {
      margin: 0.25rem;
      background: transparent;
      border: 1px solid #d1d5db;
      color: #374151;
    }
    .publication-links .button:hover {
      background: #f3f4f6;
      border-color: #9ca3af;
      color: #1f2937;
    }

    /* Section titles */
    h2.section-title,
    h3.section-title,
    h4.subsection-title,
    .title.section-title {
      color: var(--primary) !important;
      font-weight: 700;
      margin-bottom: 1.5rem;
    }
    
    h4.subsection-title {
      font-size: 1.25rem;
      margin-top: 2rem;
      margin-bottom: 1rem;
    }
    
    .section-white { background: var(--bg-white); }
    .section-gray { background: var(--bg-gray); }
    
    .insight-box {
      background: #fff;
      border: 1px solid var(--border-light);
      border-left: 4px solid var(--primary);
      padding: 1.5rem 2rem;
      border-radius: 4px;
      margin: 1.5rem 0;
    }
    
    .math-comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1.5rem;
      margin: 2rem 0;
    }
    @media (max-width: 768px) { .math-comparison { grid-template-columns: 1fr; } }
    
    .math-box {
      background: #fff;
      border-radius: 6px;
      padding: 1.5rem;
      border: 1px solid var(--border-light);
    }
    .math-box.rl { border-top: 3px solid #dc2626; }
    .math-box.ml { border-top: 3px solid var(--primary); }
    .math-box h4 { font-weight: 600; margin-bottom: 1rem; color: var(--text-dark); }
    
    .figure-container {
      background: transparent;
      border-radius: 0;
      padding: 1rem 0;
      border: none;
      margin: 1.5rem 0;
    }
    .figure-container img { border-radius: 4px; }
    .figure-caption { font-size: 0.9rem; color: var(--text-muted); margin-top: 1rem; text-align: center; }
    
    /* Equal height for analysis figures */
    .analysis-columns {
      display: flex;
      gap: 1.5rem;
      align-items: stretch;
    }
    .analysis-columns .analysis-col {
      flex: 1;
      display: flex;
    }
    .analysis-columns .figure-container {
      flex: 1;
      display: flex;
      flex-direction: column;
      margin: 0;
    }
    .analysis-columns .figure-container .img-wrapper {
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .analysis-columns .figure-container img {
      max-width: 100%;
      max-height: 280px;
      object-fit: contain;
    }
    @media (max-width: 768px) {
      .analysis-columns { flex-direction: column; }
    }
    
    .result-card {
      background: #fff;
      border-radius: 8px;
      padding: 2rem;
      margin: 1.5rem 0;
      border: 1px solid var(--border-light);
    }
    .result-card h4 { color: var(--text-dark); font-weight: 600; margin-bottom: 1rem; }
    
    .highlight-stat {
      background: var(--primary);
      color: #fff;
      padding: 0.2rem 0.6rem;
      border-radius: 4px;
      font-weight: 600;
      font-size: 0.9rem;
    }
    
    .algorithm-box {
      background: #1f2937;
      color: #e5e7eb;
      border-radius: 6px;
      padding: 1.5rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.85rem;
      overflow-x: auto;
    }
    .algorithm-box .comment { color: #9ca3af; }
    .algorithm-box .keyword { color: #f472b6; }
    .algorithm-box .function { color: #60a5fa; }
    
    table.comparison-table {
      width: 100%;
      border-collapse: collapse;
      margin: 1.5rem 0;
      background: #fff;
      border: 1px solid var(--border-light);
      border-radius: 6px;
      overflow: hidden;
    }
    table.comparison-table th {
      background: var(--primary);
      color: #fff !important;
      padding: 0.75rem 1rem;
      font-weight: 600;
      text-align: left;
    }
    table.comparison-table th * { color: #fff !important; }
    table.comparison-table th .katex, table.comparison-table th .katex * { color: #fff !important; }
    table.comparison-table td { padding: 0.75rem 1rem; border-bottom: 1px solid var(--border-light); }
    table.comparison-table tr:last-child td { border-bottom: none; }
    table.comparison-table tr:hover td { background: var(--bg-gray); }
    
    pre code { display: block; padding: 1rem; background: #1f2937; color: #e5e7eb; border-radius: 6px; overflow-x: auto; }
    .bibtex-box { 
      background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
      border: 1px solid #334155;
      border-radius: 12px; 
      padding: 1.5rem;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
    }
    .bibtex-box pre {
      margin: 0;
      background: transparent;
    }
    .bibtex-box code {
      font-family: 'JetBrains Mono', 'Fira Code', 'Monaco', monospace;
      font-size: 0.85rem;
      line-height: 1.6;
      color: #e2e8f0;
      background: transparent;
      padding: 0;
    }
    
    footer.footer { background: #1f2937; color: #9ca3af; padding: 2rem; }
    footer a { color: #93c5fd; }
    footer a:hover { color: #bfdbfe; }
    
    .emoji-icon { margin-right: 0.5rem; }
    .section { padding: 3rem 1.5rem; }
    
    .formula-box {
      background: transparent;
      border: none;
      padding: 1rem 0;
      margin: 1.5rem 0;
      text-align: center;
    }
    
    
    .conclusion-box {
      background: #fff;
      border: 1px solid var(--border-light);
      border-radius: 8px;
      padding: 2rem;
    }
    .conclusion-box p {
      line-height: 1.8;
      margin-bottom: 1rem;
    }
    .conclusion-box p:last-child {
      margin-bottom: 0;
    }
  </style>
</head>
<body>

<!-- Hero Section -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Message Passing Language Models</h1>

            <div class="is-size-5 publication-authors">
              <!-- Replace with your actual author list -->
              <span class="author-block"><a href="https://daman1209arora.github.io">Daman Arora</a><sup>*</sup>,</span>
              <span class="author-block"><a href="">Xuecheng Liu</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://gokul.dev">Gokul Swamy</a><sup></sup>,</span>
              <span class="author-block"><a href="https://azanette.com">Andrea Zanette</a><sup></sup></span>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 1rem;">
              <span class="author-block"><sup></sup>Carnegie Mellon University</span>
            </div>

            <div class="column has-text-centered" style="margin-top: 0.1rem;">
              <div class="publication-links">
                <span class="link-block">
                  <a href="ARXIV_LINK" class="external-link button is-normal is-rounded">
                    <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="PDF_LINK" class="external-link button is-normal is-rounded">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span><span>PDF</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="GITHUB_LINK" class="external-link button is-normal is-rounded">
                    <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                  </a>
                </span>
              </div>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.01rem;">
              <span class="author-block">
                <strong>TL;DR</strong> We propose a framework for language models to pass messages, allowing them to reason more efficiently.
              </span>
            </div>
            

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section section-gray">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">

      <div class="figure-container">
        <center>
          <img src="./static/images/token_scaling_with_slopes.jpg" alt="Token scaling plots" style="max-width: 100%;">
        </center>
        <p class="figure-caption" style="max-width: 64%; margin: 0 auto;">
          <strong>Scaling results on Sudoku puzzles.</strong> MPLMs achieve better scaling exponents compared to standard LLM decoding methods, enabling efficient reasoning on larger puzzles.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- ==================== TWO PERSPECTIVES ==================== -->
<section class="section section-white">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      
      <h2 class="title is-3 section-title">Introduction</h2>
      
      <p>
        For reasoning, generating long Chains-of-Thoughts (CoTs) is a computational bottleneck. Parallelism using fork and join (FJ) primitives to divide work across multiple <em>LLM threads</em> necessitates a centralized controller which increases communication costs and limits scalability. 
        In response, we introduce <strong>Message Passing Language Models</strong> (MPLMs): a novel, general-purpose framework where LLM threads can <em>spawn</em> other threads that can communicate with each other using <em>send</em> and <em>recv</em> primitives. 
      </p>
      
      <div class="figure-container">
        <center>
          <img src="./static/images/main_figure.jpg" alt="MPLM Main Figure" style="max-width: 60%;">
        </center>
        <p class="figure-caption" style="max-width: 52%; margin: 0 auto;">
          In <strong>Message Passing Language Models (MPLMs)</strong>, concurrently decoded threads communicate directly through explicit <em>send</em> and <em>recv</em> primitives and maintain a persistent context, enabling fine-grained coordination and information sharing throughout inference making them more efficient than the serial CoT and parallel Fork-Join paradigms.
        </p>
      </div>


      <!-- <div class="columns is-vcentered is-variable is-6">
  
        Left figure
        <div class="column is-6 has-text-centered">
          <img src="./static/images/main_figure.jpg"
               alt="MPLM Main Figure"
               style="max-width: 100%;">
          <p class="figure-caption" style="margin: 0.75rem auto 0;">
            In <strong>Message Passing Language Models (MPLMs)</strong>, concurrently decoded threads communicate directly through explicit
            <em>send</em> and <em>recv</em> primitives and maintain a persistent context.
          </p>
        </div>
      
        Right figure
        <div class="column is-6 has-text-centered">
          <img src="./static/images/token_scaling_with_slopes.jpg"
               alt="Token scaling plots"
               style="max-width: 100%;">
          <p class="figure-caption" style="margin: 0.75rem auto 0;">
            <strong>Scaling results on Sudoku puzzles.</strong> MPLMs achieve better scaling exponents compared to standard decoding methods.
          </p>
        </div>
      
      </div> -->
      

    </div>
  </div>
</section>

<!-- ==================== PROBABILISTIC MODELING LENS ==================== -->
<section class="section section-gray">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      
      <h2 class="title is-3 section-title">Scaling Results</h2>
    



      <div class="figure-container">
        <center>
          <img src="./static/images/mplm_results_table.png" alt="Token scaling plots" style="max-width: 70%;">
        </center>
        <p class="figure-caption" style="max-width: 64%; margin: 0 auto;">
          Average <strong>latency and accuracy</strong> across Sudoku sizes. Red cross (❌) denotes infeasible training due to context or compute constraints and a green tick
          (✅) denotes the best scalable model. MPLM remains feasible and accurate at larger grid sizes, while FJ, Serial baselines, and frontier models fail to scale.
        </p>
      </div>



      <p>
        As a proof of concept, we consider Sudoku puzzles since they are deterministic, naturally parallelizable, exhibits a complex communication structure, and allows scaling complexity incrementally.
        we theoretically and empirically show better scaling with MPLMs on Sudoku puzzles, scaling to upto 25×25 Sudoku puzzles which are challenging even for GPT-5 Pro. 
   
      </p>


    </div>
  </div>
</section>

<section class="section section-white">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title">Recipe</h2>
    
    <div class="content has-text-justified">

      <h3>Execution Control Directives</h3>
      <p>
        MPLMs use a small set of <em>directives</em>—explicit instructions generated by the model—to control execution.
        These play roles analogous to process creation, communication, synchronization, and termination in
        message-passing systems.
      </p>

      <table class="directives-table">
        <thead>
          <tr>
            <th style="text-align: center;">Directive</th>
            <th style="text-align: center;">Description</th>
            <th style="text-align: center;">Syntax</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td style="text-align: center;"><strong>Spawn</strong></td>
            <td style="text-align: center;">
              Creates new LLM threads with the given IDs and the prompt.<br>
            </td>
            <td style="text-align: center;">
              <code>&lt;spawn[id1,id2,…,idN]&gt;prompt&lt;/spawn&gt;</code>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;"><strong>Send</strong></td>
            <td style="text-align: center;">
              Sends a message to one or more specified LLM threads.<br>
            </td>
            <td style="text-align: center;">
              <code>&lt;send[id1,id2,…,idN]&gt;message&lt;/send&gt;</code>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;"><strong>Receive</strong></td>
            <td style="text-align: center;">
              Blocks execution until messages are received from the specified threads.<br>
            </td>
            <td style="text-align: center;">
              <code>&lt;recv[id1,id2,…,idN]&gt;</code>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;"><strong>Stop</strong></td>
            <td style="text-align: center;">
              Terminates execution of the current LLM thread permanently.<br>
            </td>
            <td style="text-align: center;">
              <code>&lt;stop&gt;</code>
            </td>
          </tr>
        </tbody>
      </table>
      
      <p>
        We generate CoT data for different strategies using a simple program and use Supervised Fine Tuning (SFT) on Qwen3-0.6B-Base. 
        Implementing message passing requires to implement a <em>controller</em> on top of the inference engine. 

      </p>
    </div>
    
  </div>
</section>

<!-- ==================== BIBTEX ==================== -->
<section class="section section-gray" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 section-title">BibTeX</h2>
    <div class="bibtex-box">
      <pre><code>@article{tajwar2025maxrl,
  title={Maximum Likelihood Reinforcement Learning},
  author={Tajwar, Fahim and Zeng, Guanning and Zhou, Yueer and Song, Yuda and 
          Arora, Daman and Jiang, Yiding and Schneider, Jeff and 
          Salakhutdinov, Ruslan and Feng, Haiwen and Zanette, Andrea},
  journal={arXiv preprint},
  year={2025}
}</code></pre>
    </div>
  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="#"><i class="fas fa-file-pdf"></i></a>
      <a class="icon-link" href="#" class="external-link"><i class="fab fa-github"></i></a>
    </div>
    <div class="columns is-centered">
      <p>
        Corresponding Authors: <a href="mailto:damana@andrew.cmu.edu">Daman Arora</a>, <a href="mailto:azanette@andrew.cmu.edu">Andrea Zanette</a><br>
        Template adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>